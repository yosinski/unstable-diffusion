import re
from typing import List, Optional
import openai
import pdb
import time
import numpy as np


class OpenaiModel():
    """Evaluates model from OpenAI."""

    def __init__(self, model: str, api_key: str, prompt_string: str = ''):
        """Initializes an object that can call the model.

        Args:
          model: Model name, default is text-davinci-003.
          api_key: API key.
          prompt_string: Prompt used with all test examples.
        """
        self.model = model
        self.prompt_string = prompt_string
        openai.api_key = api_key

    def call(self,
             test_example_prompt: str,
             temperature: float = 0.0,
             max_tokens: int = 128,
             stop: Optional[List[str]] = None,
             prompt: str = None):
        """Calls the model with specified arguments.

        Args:
          test_example_prompt: Test example to be appended to prompt_string, which
            is used as the prompt for the model.
          temperature: Temperature. 0 for deterministic outputs.
          max_tokens: Max number of output tokens.
          stop: Stop decoding after this token.
          prompt: Override the default prompt if not None

        Returns:
          output: API call output.
        """
        # pdb.set_trace()
        result = None
        loop_count = 0
        if prompt is None:
            if self.prompt_string != '':
                prompt_to_use = re.sub('%%', '%', self.prompt_string % test_example_prompt)
            else:
                prompt_to_use = test_example_prompt
        else:
            prompt_to_use = prompt

        while result is None and loop_count < 1: #retry when there is an error, not in use if it's 1
            try:
                response = openai.Completion.create(
                    engine=self.model,
                    prompt=prompt_to_use,
                    temperature=temperature,
                    stop=stop,
                    max_tokens=max_tokens,
                )
                # pdb.set_trace()
                result = response['choices'][0]['text']
                return result
            except:
                # try to wait a few seconds and attempt again if hitting api error
                # try 5 times, and if still failing then output "MODEL_ERROR"
                time.sleep(int(np.random.choice(range(3, 10), 1)[0]))
                loop_count += 1
                pass

        return 'MODEL_ERROR'

    def extract_answer(self,
                       model_output: str,
                       split_start: str,
                       split_end: str):
        """Extracts the answer from model outputs.

        If there is an error, return 0 as the value.

        Args:
          model_output: Output generated by the model.
          split_start: Use this token to split the start of the final answer.
          split_end: Use this token to split the end of the final answer.
        """
        # pdb.set_trace()
        if 'MODEL_ERROR' in model_output:
            return 'ERROR'

        if split_start is not None:
            if split_start in model_output:
                model_output = model_output.split(split_start)[1]
            else:
                model_output = 'ERROR'
        if split_end is not None:
            if split_end in model_output:
                model_output = model_output.split(split_end)[0]
            else:
                model_output = 'ERROR'

        return model_output

    def __repr__(self) -> str:
        return 'OpenAI Model'



class OpenaiModelChat():
    """Evaluates model from OpenAI."""

    def __init__(self, model: str, api_key: str, prompt_string: str = ''):
        """Initializes an object that can call the model.

        Args:
          model: Model name, default is text-davinci-003.
          api_key: API key.
          prompt_string: Prompt used with all test examples.
        """
        self.model = model
        self.prompt_string = prompt_string
        openai.api_key = api_key

    def call(self,
             test_example_prompt: str,
             temperature: float = 0.0,
             max_tokens: int = 128,
             stop: Optional[List[str]] = None,
             ):
        """Calls the model with specified arguments.

        Args:
          test_example_prompt: Test example to be appended to prompt_string, which
            is used as the prompt for the model.
          temperature: Temperature. 0 for deterministic outputs.
          max_tokens: Max number of output tokens.
          stop: Stop decoding after this token.
          prompt: Override the default prompt if not None

        Returns:
          output: API call output.
        """
        #system_prompt = """Your job is to echo back what a user says, but to offer back five versions of it that are increasingly more extreme and surreal, in a JSON list, where the first item in the list is the same."""
        #prompt = "I am an awful person."

        system_prompt = self.prompt_string
        user_prompt = test_example_prompt
   
        messages = [
                {"role": "system", "content": f"{system_prompt}"},
                {"role": "user", "content": user_prompt},
        ]

        # pdb.set_trace()
        result = None
        loop_count = 0
        print(messages)
        while result is None and loop_count < 1: #retry when there is an error, not in use if it's 1
            if True:
                print(messages,self.model)
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    stop=stop,
                    max_tokens=max_tokens,
                )

                #pdb.set_trace()
                result = response['choices'][0]['message']['content']
                return result
            if False:
                print("Exception in calling chat completion...")
                # try to wait a few seconds and attempt again if hitting api error
                # try 5 times, and if still failing then output "MODEL_ERROR"
                time.sleep(int(np.random.choice(range(3, 10), 1)[0]))
                loop_count += 1
                pass

        return 'MODEL_ERROR'

    def extract_answer(self,
                       model_output: str,
                       split_start: str,
                       split_end: str):
        """Extracts the answer from model outputs.

        If there is an error, return 0 as the value.

        Args:
          model_output: Output generated by the model.
          split_start: Use this token to split the start of the final answer.
          split_end: Use this token to split the end of the final answer.
        """
        # pdb.set_trace()
        if 'MODEL_ERROR' in model_output:
            return 'ERROR'

        if split_start is not None:
            if split_start in model_output:
                model_output = model_output.split(split_start)[1]
            else:
                model_output = 'ERROR'
        if split_end is not None:
            if split_end in model_output:
                model_output = model_output.split(split_end)[0]
            else:
                model_output = 'ERROR'

        return model_output

    def __repr__(self) -> str:
        return 'OpenAI Model'

